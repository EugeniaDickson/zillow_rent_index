{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cluster_data = pd.read_csv('../../data/all_areas_clusters_hier.csv') # contains clustering groups\n",
    "PCdata = pd.read_csv('../../data/zillow_withPCA.csv') # contains prinicpal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = cluster_data[['Zipcode','Date','Clusters']] # subset the cluster col + two to merge on\n",
    "pc_df = PCdata.drop(['City','State','Metro','County','SizeRank','State-County','Year'],axis=1) # the relevant PC columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_df = pc_df.merge(clusters, \"inner\", on = [\"Date\",\"Zipcode\"]) # merge on date + zipcode\n",
    "# make sure n_rows post-merge == 17751\n",
    "zillow_df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from features\n",
    "y = np.log(zillow_df['Rent']) # log-scaled\n",
    "X = zillow_df.drop('Rent',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove other features from X that will not go into the regression model\n",
    "X.drop(['Zipcode','housing_availability'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7747\n",
       "3    3965\n",
       "2    3477\n",
       "1    2562\n",
       "Name: Clusters, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummify cluster column\n",
    "X['Clusters'].value_counts() # we will drop the cluster 0 column bc its the largest of the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dummy = pd.get_dummies(X['Clusters'],prefix=\"Cluster\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat((X,cluster_dummy),axis=1).drop('Clusters',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PCARandomForest import train_test\n",
    "Xtrain,Xtest,ytrain,ytest = train_test(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ols = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLSRegression(model,Xtrain,Xtest,ytrain,ytest):\n",
    "    '''\n",
    "    Input a (tuned) model, X and y train/test df's.\n",
    "    This function will output test and training R2 as well as RMSE\n",
    "    Reminder-to-self: This is just to play around. use statsmodels to check AIC, VIF, etc.\n",
    "    '''\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    print(f'training R2: {model.score(Xtrain,ytrain)}')\n",
    "    print(f'test R2: {model.score(Xtest,ytest)}')\n",
    "    \n",
    "    ypred = model.predict(Xtest)\n",
    "    RMSE = mean_squared_error(ytest,ypred,squared=False)\n",
    "    print(f'RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "Trying just the PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_train = Xtrain.filter(regex='PC')\n",
    "pc_test = Xtest.filter(regex='PC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2: 0.48202084944712686\n",
      "test R2: 0.4441023303339105\n",
      "RMSE: 0.211323505558185\n"
     ]
    }
   ],
   "source": [
    "OLSRegression(ols,pc_train,pc_test,ytrain,ytest) # yikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLSRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "Trying with clustering cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2: 0.5048337034382637\n",
      "test R2: 0.46929249135311507\n",
      "RMSE: 0.2064800020209921\n"
     ]
    }
   ],
   "source": [
    "OLSRegression(model = ols, Xtrain = Xtrain.filter(regex='Cluster|PC'), Xtest = Xtest.filter(regex='Cluster|PC'),\n",
    "             ytrain = ytrain, ytest = ytest)\n",
    "\n",
    "# performs better with lower RMSE when including the cluster cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3\n",
    "Try everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2: 0.5714957825302953\n",
      "test R2: 0.541552111086042\n",
      "RMSE: 0.19190901142446715\n"
     ]
    }
   ],
   "source": [
    "OLSRegression(ols,Xtrain,Xtest,ytrain,ytest) # best performance but still poor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying regression in R because a stepwise approach with more information would be nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = PCdata.merge(clusters, \"inner\", on = [\"Date\",\"Zipcode\"]) # merge on date + zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dummy = pd.get_dummies(big_df['Clusters'],prefix=\"Cluster\",drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.concat((big_df,cluster_dummy),axis=1).drop('Clusters',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv('../../data/zillow_df_0331.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeah use lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "params = {\"alpha\":[0.000001, 0.0001, 0.001, 0.005, 0.01, 0.03, 0.05, 0.08, 0.1, 0.25, 0.5]}\n",
    "grid = GridSearchCV(lasso,param_grid=params, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [1e-06, 0.0001, 0.001, 0.005, 0.01, 0.03,\n",
       "                                   0.05, 0.08, 0.1, 0.25, 0.5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00841689, 0.00492058, 0.00367703, 0.00333967, 0.00328054,\n",
       "        0.00322886, 0.00325184, 0.00371075, 0.00367661, 0.00340924,\n",
       "        0.00372725]),\n",
       " 'std_fit_time': array([0.00145286, 0.00067229, 0.00027388, 0.00037857, 0.00013899,\n",
       "        0.00011543, 0.00014818, 0.00021466, 0.00021392, 0.00032545,\n",
       "        0.00019809]),\n",
       " 'mean_score_time': array([0.00243506, 0.00142999, 0.00134363, 0.00134292, 0.00135198,\n",
       "        0.00138621, 0.00144038, 0.00140548, 0.00169282, 0.00161409,\n",
       "        0.00135241]),\n",
       " 'std_score_time': array([6.73476750e-04, 1.53317303e-04, 1.11351595e-04, 1.08703353e-04,\n",
       "        1.42003963e-04, 1.55881808e-04, 3.23340763e-04, 1.46580006e-04,\n",
       "        1.36538838e-04, 1.20140728e-04, 7.91738671e-05]),\n",
       " 'param_alpha': masked_array(data=[1e-06, 0.0001, 0.001, 0.005, 0.01, 0.03, 0.05, 0.08,\n",
       "                    0.1, 0.25, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 1e-06},\n",
       "  {'alpha': 0.0001},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.005},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 0.03},\n",
       "  {'alpha': 0.05},\n",
       "  {'alpha': 0.08},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 0.25},\n",
       "  {'alpha': 0.5}],\n",
       " 'split0_test_score': array([ 0.5498624 ,  0.40514114,  0.17996362,  0.16615515,  0.14425829,\n",
       "         0.05059019, -0.04591064, -0.04591064, -0.04591064, -0.04591064,\n",
       "        -0.04591064]),\n",
       " 'split1_test_score': array([ 5.73895231e-01,  4.27568920e-01,  2.02298598e-01,  1.91158826e-01,\n",
       "         1.72621027e-01,  9.64718826e-02, -1.05181625e-05, -1.05181625e-05,\n",
       "        -1.05181625e-05, -1.05181625e-05, -1.05181625e-05]),\n",
       " 'split2_test_score': array([ 0.57142163,  0.41599669,  0.18263498,  0.17262865,  0.1565107 ,\n",
       "         0.09212431, -0.0063131 , -0.0063131 , -0.0063131 , -0.0063131 ,\n",
       "        -0.0063131 ]),\n",
       " 'split3_test_score': array([ 0.56662437,  0.41863039,  0.18777967,  0.18041812,  0.16629441,\n",
       "         0.09831012, -0.00458457, -0.00458457, -0.00458457, -0.00458457,\n",
       "        -0.00458457]),\n",
       " 'split4_test_score': array([ 0.53669992,  0.39445105,  0.16953123,  0.16491874,  0.15233462,\n",
       "         0.0960578 , -0.00808074, -0.00808074, -0.00808074, -0.00808074,\n",
       "        -0.00808074]),\n",
       " 'mean_test_score': array([ 0.55970071,  0.41235764,  0.18444162,  0.1750559 ,  0.15840381,\n",
       "         0.08671086, -0.01297991, -0.01297991, -0.01297991, -0.01297991,\n",
       "        -0.01297991]),\n",
       " 'std_test_score': array([0.01423116, 0.01146034, 0.01072987, 0.00975638, 0.01004893,\n",
       "        0.01817247, 0.01668273, 0.01668273, 0.01668273, 0.01668273,\n",
       "        0.01668273]),\n",
       " 'rank_test_score': array([1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7], dtype=int32),\n",
       " 'split0_train_score': array([0.56956315, 0.41617391, 0.19122775, 0.1812424 , 0.16377554,\n",
       "        0.08886619, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'split1_train_score': array([0.57056182, 0.42308537, 0.19659792, 0.1868129 , 0.16975543,\n",
       "        0.09686663, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'split2_train_score': array([0.57046537, 0.42587323, 0.2003256 , 0.19072625, 0.17427801,\n",
       "        0.10306122, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'split3_train_score': array([0.57184096, 0.42768776, 0.19952013, 0.1900209 , 0.17350223,\n",
       "        0.10188923, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'split4_train_score': array([0.57738736, 0.4347324 , 0.20266669, 0.19329485, 0.17672869,\n",
       "        0.10668758, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'mean_train_score': array([0.57196373, 0.42551053, 0.19806762, 0.18841946, 0.17160798,\n",
       "        0.09947417, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'std_train_score': array([0.00280728, 0.00604927, 0.00393201, 0.00414117, 0.00451039,\n",
       "        0.00616541, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
